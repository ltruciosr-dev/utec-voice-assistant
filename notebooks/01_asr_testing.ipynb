{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR (Automatic Speech Recognition) Testing Notebook\n",
    "\n",
    "This notebook tests multiple ASR models:\n",
    "1. **Whisper Small** - OpenAI's small model\n",
    "2. **Whisper Large v3 Turbo** - OpenAI's turbo model\n",
    "3. **Parakeet TDT 0.6B v3** - NVIDIA's specialized model\n",
    "\n",
    "Features:\n",
    "- Record audio from microphone\n",
    "- Save audio as WAV files\n",
    "- Compare transcription quality and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úì Running in Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚úì Running locally\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  GOOGLE COLAB SETUP\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Clone repository\n",
    "    print(\"\\n[1/3] Cloning repository...\")\n",
    "    !git clone https://github.com/ltruciosr-dev/utec-voice-assistant.git\n",
    "    \n",
    "    # Change to repo directory\n",
    "    import os\n",
    "    os.chdir('utec-voice-assistant')\n",
    "    print(\"‚úì Repository cloned\")\n",
    "    \n",
    "    # Install dependencies\n",
    "    print(\"\\n[2/3] Installing dependencies...\")\n",
    "    !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    !pip install -q -r requirements.txt\n",
    "    print(\"‚úì Dependencies installed\")\n",
    "    \n",
    "    # Verify GPU\n",
    "    print(\"\\n[3/3] Verifying GPU access...\")\n",
    "    import torch\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  SETUP COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"Skipping Colab setup (running locally)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "**Run this section if using Google Colab. Skip if running locally.**\n",
    "\n",
    "This will:\n",
    "1. Clone the repository\n",
    "2. Install dependencies\n",
    "3. Set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport numpy as np\nimport soundfile as sf\nfrom transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\nfrom transformers import AutoModelForCTC, AutoTokenizer\nimport time\nfrom pathlib import Path\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Check if running in Colab\ntry:\n    import google.colab\n    IN_COLAB = True\nexcept:\n    IN_COLAB = False\n\n# Check CUDA availability\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA version: {torch.version.cuda}\")\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Microphone Recording Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def record_audio(duration=5, sample_rate=16000, output_dir=\"recordings\"):\n    \"\"\"\n    Record audio from microphone and save as WAV file.\n    Works in both Colab and local environments.\n    \n    Args:\n        duration: Recording duration in seconds (Colab only)\n        sample_rate: Sample rate (16kHz recommended for ASR)\n        output_dir: Directory to save recordings\n    \n    Returns:\n        Path to saved WAV file\n    \"\"\"\n    from pathlib import Path\n    from datetime import datetime\n    \n    # Create output directory\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n    \n    # Generate filename with timestamp\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    filename = output_path / f\"recording_{timestamp}.wav\"\n    \n    try:\n        from google.colab import files\n        from IPython.display import Audio, display\n        import io\n        \n        # Colab environment - use browser recording\n        print(f\"üé§ Recording for {duration} seconds in Colab...\")\n        print(\"Click the record button below and speak!\")\n        \n        # Record using Colab's Audio widget\n        audio = Audio(rate=sample_rate, autoplay=False)\n        display(audio)\n        \n        # Note: In Colab, you need to manually upload or use alternative method\n        print(\"\\n‚ö†Ô∏è  Browser recording widget displayed above.\")\n        print(\"Alternative: Upload an audio file instead:\")\n        \n        uploaded = files.upload()\n        \n        if uploaded:\n            # Save uploaded file\n            upload_filename = list(uploaded.keys())[0]\n            with open(filename, 'wb') as f:\n                f.write(uploaded[upload_filename])\n            print(f\"‚úì Audio saved to: {filename}\")\n        else:\n            print(\"‚ö†Ô∏è  No file uploaded\")\n            return None\n            \n    except ImportError:\n        # Local environment - provide instructions\n        print(\"‚ö†Ô∏è  Audio recording requires manual file upload in this environment\")\n        print(\"Please upload an audio file (WAV format preferred)\")\n        print(f\"Expected location: {filename}\")\n        return None\n    \n    return str(filename)\n\n# Alternative: Simple file upload for Colab\ndef upload_audio_file():\n    \"\"\"\n    Upload audio file (works in Colab and local Jupyter).\n    \"\"\"\n    try:\n        from google.colab import files\n        from pathlib import Path\n        \n        print(\"üìÅ Upload your audio file (WAV, MP3, etc.):\")\n        uploaded = files.upload()\n        \n        if uploaded:\n            filename = list(uploaded.keys())[0]\n            print(f\"‚úì File uploaded: {filename}\")\n            return filename\n        else:\n            print(\"‚ö†Ô∏è  No file uploaded\")\n            return None\n    except ImportError:\n        print(\"‚ö†Ô∏è  File upload widget not available\")\n        print(\"Please use the file browser to add your audio file\")\n        return None\n\nprint(\"‚úì Audio functions defined\")\nprint(\"\\nFor Colab: Use upload_audio_file() to upload an audio file\")\nprint(\"Example: audio_file = upload_audio_file()\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Whisper Models Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Data type: {torch_dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Whisper Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Whisper Small model...\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "whisper_small_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    \"openai/whisper-small\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ")\n",
    "whisper_small_model.to(device)\n",
    "\n",
    "whisper_small_processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "whisper_small_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper_small_model,\n",
    "    tokenizer=whisper_small_processor.tokenizer,\n",
    "    feature_extractor=whisper_small_processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"‚úì Whisper Small loaded\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"VRAM usage: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Whisper Large v3 Turbo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Whisper Large v3 Turbo model...\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "whisper_turbo_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    \"openai/whisper-large-v3-turbo\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ")\n",
    "whisper_turbo_model.to(device)\n",
    "\n",
    "whisper_turbo_processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3-turbo\")\n",
    "\n",
    "whisper_turbo_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper_turbo_model,\n",
    "    tokenizer=whisper_turbo_processor.tokenizer,\n",
    "    feature_extractor=whisper_turbo_processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"‚úì Whisper Turbo loaded\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"VRAM usage: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 NVIDIA Parakeet TDT 0.6B v3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading NVIDIA Parakeet TDT 0.6B v3 model...\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load Parakeet model (CTC-based)\n",
    "parakeet_model = AutoModelForCTC.from_pretrained(\n",
    "    \"nvidia/parakeet-tdt-0.6b-v3\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "parakeet_model.to(device)\n",
    "\n",
    "parakeet_processor = AutoProcessor.from_pretrained(\n",
    "    \"nvidia/parakeet-tdt-0.6b-v3\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "parakeet_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=parakeet_model,\n",
    "    tokenizer=parakeet_processor.tokenizer,\n",
    "    feature_extractor=parakeet_processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"‚úì Parakeet TDT loaded\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"VRAM usage: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transcription Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_whisper(audio_path, pipe, model_name, language=\"spanish\"):\n",
    "    \"\"\"\n",
    "    Transcribe audio using Whisper models.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Transcribing with {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Clear cache and measure memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        initial_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "    \n",
    "    # Transcribe\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = pipe(\n",
    "        audio_path,\n",
    "        generate_kwargs={\"language\": language, \"task\": \"transcribe\"},\n",
    "        return_timestamps=False\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    # Memory stats\n",
    "    if torch.cuda.is_available():\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        final_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        memory_used = peak_memory - initial_memory\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nüìù Transcription: {result['text']}\")\n",
    "    print(f\"\\n‚è±Ô∏è  Inference Time: {inference_time:.3f}s\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üíæ Memory Used: {memory_used:.3f} GB\")\n",
    "        print(f\"üìä Peak Memory: {peak_memory:.3f} GB\")\n",
    "    \n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"text\": result['text'],\n",
    "        \"inference_time\": inference_time,\n",
    "        \"memory_used\": memory_used if torch.cuda.is_available() else 0\n",
    "    }\n",
    "\n",
    "\n",
    "def transcribe_with_parakeet(audio_path, pipe, model_name):\n",
    "    \"\"\"\n",
    "    Transcribe audio using Parakeet model.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Transcribing with {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Clear cache and measure memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        initial_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "    \n",
    "    # Transcribe\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = pipe(audio_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    # Memory stats\n",
    "    if torch.cuda.is_available():\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        final_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        memory_used = peak_memory - initial_memory\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nüìù Transcription: {result['text']}\")\n",
    "    print(f\"\\n‚è±Ô∏è  Inference Time: {inference_time:.3f}s\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üíæ Memory Used: {memory_used:.3f} GB\")\n",
    "        print(f\"üìä Peak Memory: {peak_memory:.3f} GB\")\n",
    "    \n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"text\": result['text'],\n",
    "        \"inference_time\": inference_time,\n",
    "        \"memory_used\": memory_used if torch.cuda.is_available() else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Record Audio and Test All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Upload or specify audio file\n# For Colab: Upload a file\n# audio_file = upload_audio_file()\n\n# Or specify existing file path\naudio_file = \"test_audio.wav\"  # Replace with your file\n\nprint(f\"Using audio file: {audio_file}\")\nprint(\"\\nüí° Tip: In Colab, run: audio_file = upload_audio_file()\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Whisper Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_small = transcribe_with_whisper(\n",
    "    audio_file,\n",
    "    whisper_small_pipe,\n",
    "    \"Whisper Small\",\n",
    "    language=\"spanish\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Whisper Large v3 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_turbo = transcribe_with_whisper(\n",
    "    audio_file,\n",
    "    whisper_turbo_pipe,\n",
    "    \"Whisper Large v3 Turbo\",\n",
    "    language=\"spanish\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test NVIDIA Parakeet TDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_parakeet = transcribe_with_parakeet(\n",
    "    audio_file,\n",
    "    parakeet_pipe,\n",
    "    \"NVIDIA Parakeet TDT 0.6B v3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compile results\n",
    "results = [result_small, result_turbo, result_parakeet]\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTranscriptions:\")\n",
    "for r in results:\n",
    "    print(f\"\\n{r['model']}:\")\n",
    "    print(f\"  {r['text']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Performance Metrics:\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df[['model', 'inference_time', 'memory_used']].to_string(index=False))\n",
    "\n",
    "# Find fastest model\n",
    "fastest = min(results, key=lambda x: x['inference_time'])\n",
    "print(f\"\\nüèÜ Fastest Model: {fastest['model']} ({fastest['inference_time']:.3f}s)\")\n",
    "\n",
    "# Find most memory efficient\n",
    "if torch.cuda.is_available():\n",
    "    most_efficient = min(results, key=lambda x: x['memory_used'])\n",
    "    print(f\"üíæ Most Memory Efficient: {most_efficient['model']} ({most_efficient['memory_used']:.3f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Testing with Multiple Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Batch testing with multiple audio files\nprint(\"‚ö†Ô∏è  Batch recording disabled in Colab-friendly version\")\nprint(\"Upload multiple files individually and test them:\")\nprint(\"\\nExample:\")\nprint(\"  audio_file = upload_audio_file()\")\nprint(\"  r_small = transcribe_with_whisper(audio_file, whisper_small_pipe, 'Whisper Small')\")\nprint(\"  r_turbo = transcribe_with_whisper(audio_file, whisper_turbo_pipe, 'Whisper Turbo')\")  \nprint(\"  r_parakeet = transcribe_with_parakeet(audio_file, parakeet_pipe, 'Parakeet TDT')\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  RECOMMENDATIONS FOR VOICE ASSISTANT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Model Characteristics:\")\n",
    "print(\"\\n1. Whisper Small:\")\n",
    "print(\"   - Fast inference (~2-3s)\")\n",
    "print(\"   - Low memory (~1.5-2GB)\")\n",
    "print(\"   - Good Spanish support\")\n",
    "print(\"   - ‚úÖ Recommended for real-time voice assistant\")\n",
    "\n",
    "print(\"\\n2. Whisper Large v3 Turbo:\")\n",
    "print(\"   - Better accuracy\")\n",
    "print(\"   - Moderate memory (~3-4GB)\")\n",
    "print(\"   - Slower than small\")\n",
    "print(\"   - Good for higher quality needs\")\n",
    "\n",
    "print(\"\\n3. NVIDIA Parakeet TDT 0.6B v3:\")\n",
    "print(\"   - Very fast (CTC-based)\")\n",
    "print(\"   - Low memory\")\n",
    "print(\"   - Multilingual support\")\n",
    "print(\"   - Alternative option for speed-critical applications\")\n",
    "\n",
    "print(\"\\nüí° For <12GB VRAM constraint:\")\n",
    "print(\"   Choose: Whisper Small or Parakeet TDT\")\n",
    "print(\"   This leaves ~8-10GB for LLM and TTS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}