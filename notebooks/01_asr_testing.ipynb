{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR (Automatic Speech Recognition) Testing Notebook\n",
    "\n",
    "This notebook tests multiple ASR models:\n",
    "1. **Whisper Small** - OpenAI's small model\n",
    "2. **Whisper Large v3 Turbo** - OpenAI's turbo model\n",
    "3. **Parakeet TDT 0.6B v3** - NVIDIA's specialized model\n",
    "\n",
    "Features:\n",
    "- Record audio from microphone\n",
    "- Save audio as WAV files\n",
    "- Compare transcription quality and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from transformers import AutoModelForCTC, AutoTokenizer\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Microphone Recording Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(duration=5, sample_rate=16000, output_dir=\"recordings\"):\n",
    "    \"\"\"\n",
    "    Record audio from microphone and save as WAV file.\n",
    "    \n",
    "    Args:\n",
    "        duration: Recording duration in seconds\n",
    "        sample_rate: Sample rate (16kHz recommended for ASR)\n",
    "        output_dir: Directory to save recordings\n",
    "    \n",
    "    Returns:\n",
    "        Path to saved WAV file\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Generate filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = output_path / f\"recording_{timestamp}.wav\"\n",
    "    \n",
    "    print(f\"üé§ Recording for {duration} seconds...\")\n",
    "    print(f\"Speak now!\")\n",
    "    \n",
    "    # Record audio\n",
    "    recording = sd.rec(\n",
    "        int(duration * sample_rate),\n",
    "        samplerate=sample_rate,\n",
    "        channels=1,\n",
    "        dtype='float32'\n",
    "    )\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    \n",
    "    # Save as WAV file\n",
    "    sf.write(filename, recording, sample_rate)\n",
    "    \n",
    "    print(f\"‚úì Recording saved to: {filename}\")\n",
    "    print(f\"Duration: {duration}s\")\n",
    "    print(f\"Sample rate: {sample_rate}Hz\")\n",
    "    \n",
    "    return str(filename)\n",
    "\n",
    "# Test the function (optional - uncomment to test)\n",
    "# test_audio = record_audio(duration=3, output_dir=\"test_recordings\")\n",
    "# print(f\"Test recording saved at: {test_audio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Whisper Models Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Data type: {torch_dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Whisper Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Whisper Small model...\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "whisper_small_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    \"openai/whisper-small\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ")\n",
    "whisper_small_model.to(device)\n",
    "\n",
    "whisper_small_processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "whisper_small_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper_small_model,\n",
    "    tokenizer=whisper_small_processor.tokenizer,\n",
    "    feature_extractor=whisper_small_processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"‚úì Whisper Small loaded\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"VRAM usage: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Whisper Large v3 Turbo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Whisper Large v3 Turbo model...\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "whisper_turbo_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    \"openai/whisper-large-v3-turbo\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ")\n",
    "whisper_turbo_model.to(device)\n",
    "\n",
    "whisper_turbo_processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3-turbo\")\n",
    "\n",
    "whisper_turbo_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper_turbo_model,\n",
    "    tokenizer=whisper_turbo_processor.tokenizer,\n",
    "    feature_extractor=whisper_turbo_processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"‚úì Whisper Turbo loaded\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"VRAM usage: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 NVIDIA Parakeet TDT 0.6B v3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading NVIDIA Parakeet TDT 0.6B v3 model...\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load Parakeet model (CTC-based)\n",
    "parakeet_model = AutoModelForCTC.from_pretrained(\n",
    "    \"nvidia/parakeet-tdt-0.6b-v3\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "parakeet_model.to(device)\n",
    "\n",
    "parakeet_processor = AutoProcessor.from_pretrained(\n",
    "    \"nvidia/parakeet-tdt-0.6b-v3\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "parakeet_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=parakeet_model,\n",
    "    tokenizer=parakeet_processor.tokenizer,\n",
    "    feature_extractor=parakeet_processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"‚úì Parakeet TDT loaded\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"VRAM usage: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transcription Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_whisper(audio_path, pipe, model_name, language=\"spanish\"):\n",
    "    \"\"\"\n",
    "    Transcribe audio using Whisper models.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Transcribing with {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Clear cache and measure memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        initial_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "    \n",
    "    # Transcribe\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = pipe(\n",
    "        audio_path,\n",
    "        generate_kwargs={\"language\": language, \"task\": \"transcribe\"},\n",
    "        return_timestamps=False\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    # Memory stats\n",
    "    if torch.cuda.is_available():\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        final_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        memory_used = peak_memory - initial_memory\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nüìù Transcription: {result['text']}\")\n",
    "    print(f\"\\n‚è±Ô∏è  Inference Time: {inference_time:.3f}s\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üíæ Memory Used: {memory_used:.3f} GB\")\n",
    "        print(f\"üìä Peak Memory: {peak_memory:.3f} GB\")\n",
    "    \n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"text\": result['text'],\n",
    "        \"inference_time\": inference_time,\n",
    "        \"memory_used\": memory_used if torch.cuda.is_available() else 0\n",
    "    }\n",
    "\n",
    "\n",
    "def transcribe_with_parakeet(audio_path, pipe, model_name):\n",
    "    \"\"\"\n",
    "    Transcribe audio using Parakeet model.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Transcribing with {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Clear cache and measure memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        initial_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "    \n",
    "    # Transcribe\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = pipe(audio_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    # Memory stats\n",
    "    if torch.cuda.is_available():\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        final_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        memory_used = peak_memory - initial_memory\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nüìù Transcription: {result['text']}\")\n",
    "    print(f\"\\n‚è±Ô∏è  Inference Time: {inference_time:.3f}s\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üíæ Memory Used: {memory_used:.3f} GB\")\n",
    "        print(f\"üìä Peak Memory: {peak_memory:.3f} GB\")\n",
    "    \n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"text\": result['text'],\n",
    "        \"inference_time\": inference_time,\n",
    "        \"memory_used\": memory_used if torch.cuda.is_available() else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Record Audio and Test All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record audio from microphone\n",
    "# Uncomment to record new audio\n",
    "# audio_file = record_audio(duration=5, output_dir=\"recordings\")\n",
    "\n",
    "# Or use an existing file\n",
    "audio_file = \"recordings/recording_20241027_120000.wav\"  # Replace with your file\n",
    "\n",
    "print(f\"Using audio file: {audio_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Whisper Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_small = transcribe_with_whisper(\n",
    "    audio_file,\n",
    "    whisper_small_pipe,\n",
    "    \"Whisper Small\",\n",
    "    language=\"spanish\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Whisper Large v3 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_turbo = transcribe_with_whisper(\n",
    "    audio_file,\n",
    "    whisper_turbo_pipe,\n",
    "    \"Whisper Large v3 Turbo\",\n",
    "    language=\"spanish\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test NVIDIA Parakeet TDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_parakeet = transcribe_with_parakeet(\n",
    "    audio_file,\n",
    "    parakeet_pipe,\n",
    "    \"NVIDIA Parakeet TDT 0.6B v3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compile results\n",
    "results = [result_small, result_turbo, result_parakeet]\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTranscriptions:\")\n",
    "for r in results:\n",
    "    print(f\"\\n{r['model']}:\")\n",
    "    print(f\"  {r['text']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Performance Metrics:\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df[['model', 'inference_time', 'memory_used']].to_string(index=False))\n",
    "\n",
    "# Find fastest model\n",
    "fastest = min(results, key=lambda x: x['inference_time'])\n",
    "print(f\"\\nüèÜ Fastest Model: {fastest['model']} ({fastest['inference_time']:.3f}s)\")\n",
    "\n",
    "# Find most memory efficient\n",
    "if torch.cuda.is_available():\n",
    "    most_efficient = min(results, key=lambda x: x['memory_used'])\n",
    "    print(f\"üíæ Most Memory Efficient: {most_efficient['model']} ({most_efficient['memory_used']:.3f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Testing with Multiple Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple recordings\n",
    "num_tests = 3  # Number of recordings to make\n",
    "duration = 5   # Duration of each recording\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i in range(num_tests):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Recording {i+1}/{num_tests}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Record audio\n",
    "    audio_file = record_audio(duration=duration, output_dir=\"batch_recordings\")\n",
    "    \n",
    "    # Test with all models\n",
    "    r_small = transcribe_with_whisper(audio_file, whisper_small_pipe, \"Whisper Small\")\n",
    "    r_turbo = transcribe_with_whisper(audio_file, whisper_turbo_pipe, \"Whisper Turbo\")\n",
    "    r_parakeet = transcribe_with_parakeet(audio_file, parakeet_pipe, \"Parakeet TDT\")\n",
    "    \n",
    "    all_results.append({\n",
    "        \"recording\": i+1,\n",
    "        \"file\": audio_file,\n",
    "        \"results\": [r_small, r_turbo, r_parakeet]\n",
    "    })\n",
    "    \n",
    "    time.sleep(2)  # Pause between recordings\n",
    "\n",
    "print(\"\\n‚úì Batch testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  RECOMMENDATIONS FOR VOICE ASSISTANT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Model Characteristics:\")\n",
    "print(\"\\n1. Whisper Small:\")\n",
    "print(\"   - Fast inference (~2-3s)\")\n",
    "print(\"   - Low memory (~1.5-2GB)\")\n",
    "print(\"   - Good Spanish support\")\n",
    "print(\"   - ‚úÖ Recommended for real-time voice assistant\")\n",
    "\n",
    "print(\"\\n2. Whisper Large v3 Turbo:\")\n",
    "print(\"   - Better accuracy\")\n",
    "print(\"   - Moderate memory (~3-4GB)\")\n",
    "print(\"   - Slower than small\")\n",
    "print(\"   - Good for higher quality needs\")\n",
    "\n",
    "print(\"\\n3. NVIDIA Parakeet TDT 0.6B v3:\")\n",
    "print(\"   - Very fast (CTC-based)\")\n",
    "print(\"   - Low memory\")\n",
    "print(\"   - Multilingual support\")\n",
    "print(\"   - Alternative option for speed-critical applications\")\n",
    "\n",
    "print(\"\\nüí° For <12GB VRAM constraint:\")\n",
    "print(\"   Choose: Whisper Small or Parakeet TDT\")\n",
    "print(\"   This leaves ~8-10GB for LLM and TTS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
